---
author: Michael Taylor
category: articles
source: reader
date: 2025-11-18
URL: https://every.to/also-true-for-humans/how-to-grade-ai-and-why-you-should-d4557c4c-b427-4cfb-a097-d9aaaf099cff
---
Michael Taylor #reader

## Summary
Evals are often all you need

## Highlights
To paraphrase [Picasso](https://www.goodreads.com/quotes/485128-when-art-critics-get-together-they-talk-about-form-and), when AI experts get together, they talk about transformers and GPUs and AI safety. When prompt engineers get together, they talk about how to run cheap evals.Evals, short for “evaluation metrics,” are how we measure alignment between AI responses and business goals, as well as the accuracy, reliability, and quality of AI responses. ([View Highlight](https://read.readwise.io/read/01jgtm7tydj62n0j1mtme7m8ey))

.As OpenAI cofounder and president [Greg Brockman](https://twitter.com/gdb/status/1733553161884127435) puts it, “evals are surprisingly often all you need.” Benchmarking can tell you which models are worth trying, but there’s no substitute for evals. If you’re a practitioner, it doesn’t matter whether the AI can pass the [bar exam](https://www.iit.edu/news/gpt-4-passes-bar-exam) or [qualify as a CFA](https://www.businessinsider.com/list-here-are-the-exams-chatgpt-has-passed-so-far-2023-1), as benchmarks tend to discern. Evaluations can’t capture [how it feels](https://every.to/napkin-math/claude-3-is-the-most-human-ai-yet) to talk to a model. What matters is if they work for you. ([View Highlight](https://read.readwise.io/read/01jgtmanend82patqnzbtz5dkw))

.In my experience as a prompt engineer, 80–90 percent of my work involves building evals, testing new ones, and trying to beat previous benchmarks. Evals are so important that OpenAI [open-sourced](https://github.com/openai/evals) its eval framework to encourage third-party contributions to its question-and-answer test sets to make them more diverse. ([View Highlight](https://read.readwise.io/read/01jgtmby2axajv7s3qcnp8j2pk))

